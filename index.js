import express from "express";
import axios from "axios";
import dotenv from "dotenv";

dotenv.config();

const app = express();
app.use(express.json());

// Render ä¼šä¼  PORTï¼Œæ²¡ä¼ å°±ç”¨ 3000ï¼Œæœ¬åœ°ä¹Ÿèƒ½è·‘
const PORT = process.env.PORT || 3000;
const OPENAI_API_KEY = process.env.OPENAI_API_KEY;

// ====== é€šç”¨ï¼šè°ƒç”¨ OpenAI ======
async function callLLM(prompt) {
  if (!OPENAI_API_KEY) {
    throw new Error("ç¼ºå°‘ OPENAI_API_KEYï¼Œè¯·åœ¨ Render çŽ¯å¢ƒå˜é‡é‡Œé…ç½®ã€‚");
  }

  const res = await axios.post(
    "https://api.openai.com/v1/chat/completions",
    {
      model: "gpt-4o-mini",
      messages: [
        {
          role: "system",
          content: "ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½åŠ©ç†ï¼Œæ“…é•¿è‡ªåŠ¨è§„åˆ’å’Œä¼˜åŒ–ä¸»æ’­çš„ç”Ÿæ„å†³ç­–ã€‚"
        },
        { role: "user", content: prompt }
      ]
    },
    {
      headers: {
        Authorization: `Bearer ${OPENAI_API_KEY}`,
        "Content-Type": "application/json"
      }
    }
  );

  return res.data.choices[0].message.content.trim();
}

// ====== è·¯ç”± 1ï¼šé¦–é¡µï¼Œè¯æ˜ŽæœåŠ¡æ´»ç€ ======
app.get("/", (req, res) => {
  res.send("AI Orchestrator æ­£åœ¨è¿è¡Œ ðŸš€ ï¼Œè®¿é—® /demo çœ‹ç¤ºä¾‹ã€‚");
});

// ====== è·¯ç”± 2ï¼šå¤šè§’è‰² Demoï¼ˆä½ çŽ°åœ¨æœ€éœ€è¦çš„ï¼‰ ======
// GET https://ä½ çš„åŸŸå/demo ç›´æŽ¥åœ¨æµè§ˆå™¨çœ‹ç»“æžœ
app.get("/demo", async (req, res) => {
  const goal =
    "ä¸ºä¸€ä¸ªæžç¬‘å¸…å“¥äººè®¾ã€ç²‰ä¸ä¸»è¦æ˜¯20-30å²å¥³ç”Ÿçš„æŠ–éŸ³å¸¦è´§ç›´æ’­é—´ï¼Œè®¾è®¡3ä¸ªé€‚åˆçš„çˆ†æ¬¾æ–¹å‘ï¼Œå¹¶è¯´æ˜Žé€‰å“é€»è¾‘å’Œç›´æ’­åˆ‡å…¥ç‚¹ã€‚";

  try {
    // ä¸‰ä¸ªâ€œè™šæ‹Ÿå‘˜å·¥â€çš„æ€è€ƒ
    const prompts = [
      {
        name: "é€‰å“åˆ†æžå¸ˆ",
        text:
          `ä½ æ˜¯é€‰å“åˆ†æžå¸ˆã€‚ç›®æ ‡ï¼š${goal}\n` +
          "ä»Žæˆæœ¬ã€æ¯›åˆ©ã€å¤è´­çŽ‡ã€ä¾›åº”é“¾ç¨³å®šæ€§è§’åº¦ç»™å‡ºå»ºè®®ï¼Œç”¨è¦ç‚¹åˆ—å‡ºæ¥ã€‚"
      },
      {
        name: "å†…å®¹ç­–åˆ’",
        text:
          `ä½ æ˜¯å†…å®¹ç­–åˆ’ã€‚ç›®æ ‡ï¼š${goal}\n` +
          "ç»™æ¯ä¸ªæ–¹å‘è®¾è®¡1å¥çŸ­è§†é¢‘é’©å­ + 1å¥ç›´æ’­é—´è¯æœ¯ï¼Œå£è¯­åŒ–ã€‚"
      },
      {
        name: "é£ŽæŽ§è€æ¿",
        text:
          `ä½ æ˜¯é£ŽæŽ§å…¼è€æ¿ã€‚ç›®æ ‡ï¼š${goal}\n` +
          "ç­›æŽ‰ä¸é è°±æ–¹æ¡ˆï¼Œåªä¿ç•™ä½ è®¤ä¸ºæœ€æœ‰æœºä¼šèµšåˆ°çœŸé‡‘ç™½é“¶çš„2-3æ¡ï¼Œå¹¶è§£é‡Šé£Žé™©ç‚¹ã€‚"
      }
    ];

    const steps = [];
    for (const p of prompts) {
      const out = await callLLM(p.text);
      steps.push({ agent: p.name, output: out });
    }

    // æœ€åŽç”±â€œæ€»è´Ÿè´£äººâ€ç»¼åˆ
    const summaryPrompt =
      "ä¸‹é¢æ˜¯å›¢é˜Ÿä¸åŒè§’è‰²çš„å»ºè®®ï¼Œè¯·ä½ ä½œä¸ºæ€»è´Ÿè´£äººï¼Œæ•´ç†æˆä¸€ä»½å¯æ‰§è¡Œçš„è¡ŒåŠ¨æ–¹æ¡ˆï¼ŒæŽ§åˆ¶åœ¨600å­—ä»¥å†…ï¼Œç”¨123åˆ†ç‚¹å†™æ¸…æ¥šè¦åšä»€ä¹ˆï¼š\n\n" +
      JSON.stringify(steps, null, 2);

    const finalPlan = await callLLM(summaryPrompt);

    res.setHeader("Content-Type", "text/plain; charset=utf-8");
    res.send(
      "ã€ç›®æ ‡ã€‘\n" +
        goal +
        "\n\nã€å„è§’è‰²è¾“å‡ºã€‘\n" +
        steps
          .map(
            (s) => `â€”â€” ${s.agent} â€”â€”\n${s.output}\n`
          )
          .join("\n") +
        "\nã€æ€»è´Ÿè´£äººç»™ä½ çš„æ‰§è¡Œæ–¹æ¡ˆã€‘\n" +
        finalPlan +
        "\n"
    );
  } catch (err) {
    console.error(err);
    res
      .status(500)
      .send("å‡ºé”™äº†ï¼š" + (err.response?.data?.error?.message || err.message));
  }
});

// ====== å¯åŠ¨æœåŠ¡ ======
app.listen(PORT, () => {
  console.log(`AI Orchestrator running on port ${PORT}`);
});
